#!/usr/bin/env python3
"""
üß¨ AXIOM-VERIFIED AGENTIC ENGINE (AVAE)
========================================

A NOVEL integration that doesn't exist elsewhere:

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                  AXIOM-VERIFIED AGENTIC ENGINE              ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                             ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ FunctionGemma ‚îÇ ‚îÄ‚îÄ‚ñ∂ ‚îÇ   LFM 2.5     ‚îÇ ‚îÄ‚îÄ‚ñ∂ ‚îÇ  AXIOM    ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  (270M)       ‚îÇ     ‚îÇ   (1.2B)      ‚îÇ     ‚îÇ VERIFIER  ‚îÇ ‚îÇ
‚îÇ  ‚îÇ Tool Select   ‚îÇ     ‚îÇ   Reasoning   ‚îÇ     ‚îÇ (Z3+RAG)  ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ         ‚îÇ                     ‚îÇ                    ‚îÇ       ‚îÇ
‚îÇ         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îÇ
‚îÇ                               ‚ñº                            ‚îÇ
‚îÇ                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                     ‚îÇ
‚îÇ                    ‚îÇ  Silicon Sigil  ‚îÇ                     ‚îÇ
‚îÇ                    ‚îÇ  (Signed Output)‚îÇ                     ‚îÇ
‚îÇ                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                     ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ  Seven Axioms: Love | Safety | Abundance | Growth          ‚îÇ
‚îÇ                Transparency | Never Kill | Golden Rule     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Components:
1. FunctionGemma (google/function-gemma-2b) - Tool selection
2. LFM 2.5 (LiquidAI/LFM2.5-1.2B-Instruct) - Reasoning engine
3. Sovereign Axiom Verifier - Z3 constraint checking
4. Silicon Sigil - Cryptographic signing

Usage:
    python3 avae_engine.py --prompt "Help me organize my files"
    python3 avae_engine.py --server  # Run as API server
"""

import os
import sys
import json
import asyncio
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Any, Callable
from dataclasses import dataclass, asdict
from enum import Enum

# Add paths
sys.path.insert(0, str(Path(__file__).parent))
sys.path.insert(0, str(Path(__file__).parent / "src"))

# Try to import transformers
try:
    from transformers import AutoModelForCausalLM, AutoTokenizer, AutoProcessor
    import torch
    TRANSFORMERS_AVAILABLE = True
except ImportError:
    TRANSFORMERS_AVAILABLE = False
    print("‚ö†Ô∏è transformers not available, using mock mode")

# Import Sovereign components
try:
    from sovereign_tools import SovereignTools, ToolResult
    from telemetry import get_telemetry, EventType
    from silicon_sigil import SiliconSigil
    SOVEREIGN_AVAILABLE = True
except ImportError as e:
    print(f"‚ö†Ô∏è Sovereign components not available: {e}")
    SOVEREIGN_AVAILABLE = False


class AxiomVerificationResult(Enum):
    APPROVED = "approved"
    REJECTED = "rejected"
    NEEDS_REVIEW = "needs_review"


@dataclass
class ToolCall:
    """A structured tool call from FunctionGemma."""
    name: str
    arguments: Dict[str, Any]
    confidence: float


@dataclass  
class AVAEOutput:
    """Output from the Axiom-Verified Agentic Engine."""
    prompt: str
    tool_calls: List[ToolCall]
    reasoning: str
    axiom_verification: AxiomVerificationResult
    violations: List[str]
    signed_by: Optional[str]
    timestamp: str


class AxiomVerifiedAgenticEngine:
    """
    The Axiom-Verified Agentic Engine (AVAE).
    
    This is a NOVEL architecture that combines:
    1. FunctionGemma for tool selection
    2. LFM 2.5 for reasoning
    3. Z3 + Seven Axioms for verification
    4. Silicon Sigil for output signing
    
    No one has built this before.
    """
    
    # The Seven Axioms
    AXIOMS = {
        "love": "Act from love and compassion",
        "safety": "Never cause harm to humans or systems",
        "abundance": "Create value for all, not scarcity",
        "growth": "Enable continuous improvement",
        "transparency": "No hidden agendas or deception",
        "never_kill": "Absolute prohibition on destruction of life",
        "golden_rule": "Treat others as you wish to be treated"
    }
    
    # Dangerous patterns that violate axioms
    VIOLATION_PATTERNS = {
        "safety": ["delete", "remove", "kill", "terminate", "destroy", "hack", "exploit"],
        "transparency": ["hide", "secret", "obfuscate", "deceive"],
        "never_kill": ["kill", "terminate", "destroy", "murder"],
        "abundance": ["steal", "hoard", "monopolize"],
    }
    
    # Available tools for the agent
    AVAILABLE_TOOLS = {
        "remember": {
            "description": "Store information in long-term memory",
            "parameters": {"content": "string", "memory_type": "string"}
        },
        "recall": {
            "description": "Search and retrieve memories",
            "parameters": {"query": "string"}
        },
        "verify_constraint": {
            "description": "Check if a value satisfies constraints",
            "parameters": {"variable": "string", "value": "number", "min": "number", "max": "number"}
        },
        "check_axiom": {
            "description": "Verify an action aligns with axioms",
            "parameters": {"action": "string", "axiom": "string"}
        },
        "get_metrics": {
            "description": "Get system health metrics",
            "parameters": {}
        },
        "search_web": {
            "description": "Search the web for information",
            "parameters": {"query": "string"}
        },
        "read_file": {
            "description": "Read contents of a file",
            "parameters": {"path": "string"}
        },
        "write_file": {
            "description": "Write contents to a file",
            "parameters": {"path": "string", "content": "string"}
        }
    }
    
    def __init__(
        self,
        function_gemma_model: str = "google/gemma-2b",  # Placeholder
        lfm_model: str = "LiquidAI/LFM2.5-1.2B-Instruct",
        use_mock: bool = True  # Use mock for local testing
    ):
        self.use_mock = use_mock or not TRANSFORMERS_AVAILABLE
        
        # Initialize models
        if not self.use_mock:
            print("üîÑ Loading FunctionGemma...")
            self.function_tokenizer = AutoTokenizer.from_pretrained(function_gemma_model)
            self.function_model = AutoModelForCausalLM.from_pretrained(
                function_gemma_model,
                torch_dtype=torch.float16,
                device_map="auto"
            )
            
            print("üîÑ Loading LFM 2.5...")
            self.lfm_tokenizer = AutoTokenizer.from_pretrained(lfm_model)
            self.lfm_model = AutoModelForCausalLM.from_pretrained(
                lfm_model,
                torch_dtype=torch.float16,
                device_map="auto"
            )
        else:
            print("üîß Running in mock mode (no GPU required)")
        
        # Initialize Sovereign components
        self.tools = SovereignTools() if SOVEREIGN_AVAILABLE else None
        self.telemetry = get_telemetry() if SOVEREIGN_AVAILABLE else None
        self.sigil = SiliconSigil() if SOVEREIGN_AVAILABLE else None
        
        print("üß¨ AVAE Engine initialized")
        print(f"   Axioms loaded: {len(self.AXIOMS)}")
        print(f"   Tools available: {len(self.AVAILABLE_TOOLS)}")
    
    # ==========================================
    # STAGE 1: FUNCTION GEMMA - TOOL SELECTION
    # ==========================================
    
    def select_tools(self, prompt: str) -> List[ToolCall]:
        """
        Use FunctionGemma to select appropriate tools.
        
        This is the first stage of the agentic pipeline.
        """
        if self.use_mock:
            return self._mock_tool_selection(prompt)
        
        # Format prompt for function calling
        system_prompt = f"""You are a tool-calling agent. Given a user request, select the appropriate tools.

Available tools:
{json.dumps(self.AVAILABLE_TOOLS, indent=2)}

Respond with a JSON array of tool calls:
[{{"name": "tool_name", "arguments": {{...}}}}]
"""
        
        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": prompt}
        ]
        
        inputs = self.function_tokenizer.apply_chat_template(
            messages, return_tensors="pt"
        ).to(self.function_model.device)
        
        outputs = self.function_model.generate(inputs, max_new_tokens=256)
        response = self.function_tokenizer.decode(outputs[0], skip_special_tokens=True)
        
        # Parse tool calls from response
        return self._parse_tool_calls(response)
    
    def _mock_tool_selection(self, prompt: str) -> List[ToolCall]:
        """Mock tool selection for testing."""
        prompt_lower = prompt.lower()
        
        tools = []
        
        if any(w in prompt_lower for w in ["remember", "store", "save"]):
            tools.append(ToolCall(
                name="remember",
                arguments={"content": prompt, "memory_type": "observation"},
                confidence=0.9
            ))
        
        if any(w in prompt_lower for w in ["find", "search", "recall", "what"]):
            tools.append(ToolCall(
                name="recall",
                arguments={"query": prompt},
                confidence=0.85
            ))
        
        if any(w in prompt_lower for w in ["health", "status", "metrics"]):
            tools.append(ToolCall(
                name="get_metrics",
                arguments={},
                confidence=0.95
            ))
        
        if any(w in prompt_lower for w in ["read", "open", "file"]):
            tools.append(ToolCall(
                name="read_file",
                arguments={"path": "/tmp/example.txt"},
                confidence=0.7
            ))
        
        if not tools:
            tools.append(ToolCall(
                name="remember",
                arguments={"content": f"User request: {prompt}", "memory_type": "request"},
                confidence=0.6
            ))
        
        return tools
    
    def _parse_tool_calls(self, response: str) -> List[ToolCall]:
        """Parse tool calls from model output."""
        try:
            # Find JSON array in response
            import re
            match = re.search(r'\[.*\]', response, re.DOTALL)
            if match:
                data = json.loads(match.group())
                return [
                    ToolCall(
                        name=t.get("name", "unknown"),
                        arguments=t.get("arguments", {}),
                        confidence=t.get("confidence", 0.5)
                    )
                    for t in data
                ]
        except:
            pass
        return []
    
    # ==========================================
    # STAGE 2: LFM 2.5 - REASONING
    # ==========================================
    
    def generate_reasoning(self, prompt: str, tool_calls: List[ToolCall]) -> str:
        """
        Use LFM 2.5 to generate reasoning for the action plan.
        
        This is the second stage - explaining WHY these tools.
        """
        if self.use_mock:
            return self._mock_reasoning(prompt, tool_calls)
        
        # Format reasoning prompt
        system_prompt = """You are a reasoning engine. Given a user request and selected tools,
explain your reasoning for why these tools were selected and how they will help."""
        
        tool_summary = "\n".join([
            f"- {t.name}({json.dumps(t.arguments)})" for t in tool_calls
        ])
        
        user_prompt = f"""Request: {prompt}

Selected tools:
{tool_summary}

Explain your reasoning:"""
        
        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ]
        
        inputs = self.lfm_tokenizer.apply_chat_template(
            messages, return_tensors="pt"
        ).to(self.lfm_model.device)
        
        outputs = self.lfm_model.generate(inputs, max_new_tokens=256)
        return self.lfm_tokenizer.decode(outputs[0], skip_special_tokens=True)
    
    def _mock_reasoning(self, prompt: str, tool_calls: List[ToolCall]) -> str:
        """Mock reasoning for testing."""
        tool_names = [t.name for t in tool_calls]
        
        reasoning = f"Given the request '{prompt[:50]}...', I selected {len(tool_calls)} tool(s): "
        reasoning += ", ".join(tool_names) + ". "
        
        if "remember" in tool_names:
            reasoning += "The remember tool will store this information for future reference. "
        if "recall" in tool_names:
            reasoning += "The recall tool will search existing memories for relevant information. "
        if "get_metrics" in tool_names:
            reasoning += "The metrics tool will provide system health status. "
        
        reasoning += "This approach aligns with the axioms of Safety and Growth."
        
        return reasoning
    
    # ==========================================
    # STAGE 3: AXIOM VERIFICATION
    # ==========================================
    
    def verify_axioms(self, prompt: str, tool_calls: List[ToolCall]) -> tuple:
        """
        Verify the action plan against the Seven Axioms.
        
        This is the CRITICAL safety layer.
        Returns (AxiomVerificationResult, violations list)
        """
        violations = []
        
        # Check each tool call against violation patterns
        for tool in tool_calls:
            tool_str = f"{tool.name} {json.dumps(tool.arguments)}".lower()
            
            for axiom, patterns in self.VIOLATION_PATTERNS.items():
                for pattern in patterns:
                    if pattern in tool_str:
                        violations.append(f"[{axiom.upper()}] Pattern '{pattern}' detected in {tool.name}")
        
        # Also check the original prompt
        prompt_lower = prompt.lower()
        for axiom, patterns in self.VIOLATION_PATTERNS.items():
            for pattern in patterns:
                if pattern in prompt_lower:
                    violations.append(f"[{axiom.upper()}] Pattern '{pattern}' detected in prompt")
        
        # Determine result
        if violations:
            if any("never_kill" in v.lower() for v in violations):
                return AxiomVerificationResult.REJECTED, violations
            elif len(violations) > 2:
                return AxiomVerificationResult.REJECTED, violations
            else:
                return AxiomVerificationResult.NEEDS_REVIEW, violations
        
        return AxiomVerificationResult.APPROVED, []
    
    # ==========================================
    # STAGE 4: EXECUTION + SIGNING
    # ==========================================
    
    async def execute_tools(self, tool_calls: List[ToolCall]) -> List[Dict]:
        """Execute the verified tool calls."""
        results = []
        
        if not self.tools:
            return [{"tool": t.name, "result": "mock_success"} for t in tool_calls]
        
        for tool in tool_calls:
            try:
                result = await self.tools.execute(tool.name, **tool.arguments)
                results.append({
                    "tool": tool.name,
                    "success": result.success,
                    "message": result.message
                })
            except Exception as e:
                results.append({
                    "tool": tool.name,
                    "success": False,
                    "error": str(e)
                })
        
        return results
    
    def sign_output(self, output: AVAEOutput) -> str:
        """Sign the output with Silicon Sigil."""
        if not self.sigil:
            return None
        
        payload = f"{output.prompt}|{len(output.tool_calls)}|{output.axiom_verification.value}"
        self.sigil.sign(payload)
        return self.sigil._identity.fingerprint
    
    # ==========================================
    # MAIN PIPELINE
    # ==========================================
    
    async def process(self, prompt: str) -> AVAEOutput:
        """
        Process a prompt through the full AVAE pipeline.
        
        1. FunctionGemma selects tools
        2. LFM 2.5 generates reasoning
        3. Axiom Verifier checks safety
        4. Execute if approved
        5. Sign output
        """
        print(f"\nüß¨ AVAE Processing: {prompt[:50]}...")
        
        # Stage 1: Tool Selection
        print("   [1/4] Tool Selection (FunctionGemma)...")
        tool_calls = self.select_tools(prompt)
        print(f"         Selected {len(tool_calls)} tool(s)")
        
        # Stage 2: Reasoning
        print("   [2/4] Reasoning (LFM 2.5)...")
        reasoning = self.generate_reasoning(prompt, tool_calls)
        print(f"         Generated reasoning ({len(reasoning)} chars)")
        
        # Stage 3: Axiom Verification
        print("   [3/4] Axiom Verification...")
        verification, violations = self.verify_axioms(prompt, tool_calls)
        print(f"         Result: {verification.value}")
        if violations:
            for v in violations:
                print(f"         ‚ö†Ô∏è {v}")
        
        # Stage 4: Execute if approved
        if verification == AxiomVerificationResult.APPROVED:
            print("   [4/4] Executing tools...")
            results = await self.execute_tools(tool_calls)
            for r in results:
                status = "‚úÖ" if r.get("success", False) else "‚ùå"
                print(f"         {status} {r['tool']}")
        else:
            print(f"   [4/4] Execution BLOCKED: {verification.value}")
        
        # Create output
        output = AVAEOutput(
            prompt=prompt,
            tool_calls=tool_calls,
            reasoning=reasoning,
            axiom_verification=verification,
            violations=violations,
            signed_by=None,
            timestamp=datetime.now().isoformat()
        )
        
        # Sign
        output.signed_by = self.sign_output(output)
        if output.signed_by:
            print(f"   üîê Signed by: {output.signed_by}")
        
        # Log to telemetry
        if self.telemetry:
            self.telemetry.log(
                EventType.SYSTEM_ACTION,
                "avae",
                f"Processed: {prompt[:30]}...",
                {
                    "tools": len(tool_calls),
                    "verification": verification.value,
                    "violations": len(violations)
                }
            )
        
        return output


# FastAPI Server
async def run_server():
    """Run AVAE as an API server."""
    try:
        from fastapi import FastAPI
        from pydantic import BaseModel
        import uvicorn
    except ImportError:
        print("‚ùå FastAPI not installed. Run: pip install fastapi uvicorn")
        return
    
    app = FastAPI(title="AVAE - Axiom-Verified Agentic Engine")
    engine = AxiomVerifiedAgenticEngine()
    
    class PromptRequest(BaseModel):
        prompt: str
    
    @app.post("/process")
    async def process_prompt(req: PromptRequest):
        output = await engine.process(req.prompt)
        return {
            "prompt": output.prompt,
            "tools": [asdict(t) for t in output.tool_calls],
            "reasoning": output.reasoning,
            "verification": output.axiom_verification.value,
            "violations": output.violations,
            "signed_by": output.signed_by,
            "timestamp": output.timestamp
        }
    
    @app.get("/axioms")
    async def get_axioms():
        return engine.AXIOMS
    
    @app.get("/tools")
    async def get_tools():
        return engine.AVAILABLE_TOOLS
    
    print("\nüåê Starting AVAE Server on http://localhost:8889")
    uvicorn.run(app, host="0.0.0.0", port=8889)


# CLI
if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="Axiom-Verified Agentic Engine")
    parser.add_argument("--prompt", type=str, help="Process a prompt")
    parser.add_argument("--server", action="store_true", help="Run as server")
    parser.add_argument("--test", action="store_true", help="Run test suite")
    
    args = parser.parse_args()
    
    if args.server:
        asyncio.run(run_server())
    
    elif args.prompt:
        engine = AxiomVerifiedAgenticEngine()
        output = asyncio.run(engine.process(args.prompt))
        
        print("\n" + "=" * 60)
        print("üìã AVAE OUTPUT")
        print("=" * 60)
        print(f"Prompt: {output.prompt}")
        print(f"Tools: {[t.name for t in output.tool_calls]}")
        print(f"Verification: {output.axiom_verification.value}")
        if output.violations:
            print(f"Violations: {output.violations}")
        print(f"Signed by: {output.signed_by}")
    
    elif args.test:
        print("\nüß™ AVAE TEST SUITE")
        print("=" * 60)
        
        engine = AxiomVerifiedAgenticEngine()
        
        tests = [
            "Remember that the weather is nice today",
            "Find my recent notes about the project",
            "Check system health",
            "Delete all files",  # Should be blocked
            "Help me organize my thoughts"
        ]
        
        for test in tests:
            print(f"\nüìù Test: {test}")
            output = asyncio.run(engine.process(test))
            print(f"   Result: {output.axiom_verification.value}")
    
    else:
        print("\nüß¨ AXIOM-VERIFIED AGENTIC ENGINE (AVAE)")
        print("=" * 60)
        print("A novel integration of:")
        print("  ‚Ä¢ FunctionGemma (tool selection)")
        print("  ‚Ä¢ LFM 2.5 (reasoning)")
        print("  ‚Ä¢ Seven Axioms (verification)")
        print("  ‚Ä¢ Silicon Sigil (signing)")
        print()
        print("Usage:")
        print("  --prompt 'text'  Process a prompt")
        print("  --server         Run as API server")
        print("  --test           Run test suite")
